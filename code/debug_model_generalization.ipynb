{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Model Generalization\n",
    "Here we will look at what the models are predicting for particular trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import six\n",
    "import dynamics_model_class as dmc\n",
    "import mcts_tests as mc\n",
    "import mcts\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib.pyplot import *\n",
    "import dataset_utils\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import copy\n",
    "\n",
    "from concept_dependency_graph import ConceptDependencyGraph\n",
    "import data_generator as dg\n",
    "from student import *\n",
    "import simple_mdp as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2a-w5-n100000-l8-random.pickle\n"
     ]
    }
   ],
   "source": [
    "n_concepts = 5\n",
    "use_student2 = True\n",
    "transition_after = True\n",
    "student2_str = ('2' if use_student2 else '') + ('a' if use_student2 and transition_after else '')\n",
    "learn_prob = 0.5\n",
    "lp_str = '-lp{}'.format(int(learn_prob*100)) if not use_student2 else ''\n",
    "n_students = 100000\n",
    "seqlen = 8\n",
    "filter_mastery = False\n",
    "filter_str = '' if not filter_mastery else '-filtered'\n",
    "policy = 'random'\n",
    "epsilon = 0.3\n",
    "epsilon_str = '{:.2f}'.format(epsilon) if policy == 'egreedy' else ''\n",
    "filename = 'test{}-w{}-n{}-l{}{}-{}{}{}.pickle'.format(student2_str, n_concepts, n_students, seqlen,\n",
    "                                                    lp_str, policy, epsilon_str, filter_str)\n",
    "concept_tree = ConceptDependencyGraph()\n",
    "concept_tree.init_default_tree(n_concepts)\n",
    "if not use_student2:\n",
    "    test_student = Student(n=n_concepts,p_trans_satisfied=learn_prob, p_trans_not_satisfied=0.0, p_get_ex_correct_if_concepts_learned=1.0)\n",
    "else:\n",
    "    test_student = Student2(n_concepts, transition_after=transition_after)\n",
    "six.print_(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = dataset_utils.load_data(filename='{}{}'.format(dg.SYN_DATA_DIR, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average posttest: 0.421166\n",
      "Average sparse reward: 0.00041\n",
      "Percent of full posttest score: 0.00041\n",
      "Percent of all seen: 0.4283\n",
      "(array([ 0.,  0.,  0.,  0.,  1.]), False, array([ 1.,  0.,  0.,  0.,  0.]), array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "(array([ 1.,  0.,  0.,  0.,  0.]), True, array([ 1.,  0.,  0.,  0.,  0.]), array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
      "(array([ 0.,  0.,  0.,  1.,  0.]), False, array([ 1.,  0.,  0.,  0.,  0.]), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0]))\n",
      "(array([ 1.,  0.,  0.,  0.,  0.]), True, array([ 1.,  0.,  0.,  0.,  0.]), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0]))\n",
      "(array([ 0.,  0.,  0.,  1.,  0.]), False, array([ 1.,  0.,  0.,  0.,  0.]), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0]))\n",
      "(array([ 1.,  0.,  0.,  0.,  0.]), True, array([ 1.,  0.,  0.,  0.,  0.]), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0]))\n",
      "(array([ 1.,  0.,  0.,  0.,  0.]), True, array([ 1.,  0.,  0.,  0.,  0.]), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0]))\n",
      "(array([ 0.,  0.,  0.,  0.,  1.]), False, array([ 1.,  0.,  0.,  0.,  0.]), array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0]))\n",
      "41\n",
      "[4780, 5417, 6024, 6256, 9118, 12969, 18995, 21367, 23463, 25453, 28569, 31912, 31915, 32902, 35616, 36467, 40666, 46830, 47157, 48906, 50004, 50699, 57383, 58572, 60483, 61000, 61135, 63013, 64053, 65263, 69344, 71353, 76925, 79758, 82176, 82248, 82473, 84056, 89488, 93979, 99594]\n"
     ]
    }
   ],
   "source": [
    "print('Average posttest: {}'.format(sm.expected_reward(data)))\n",
    "print('Average sparse reward: {}'.format(sm.expected_sparse_reward(data)))\n",
    "print('Percent of full posttest score: {}'.format(sm.percent_complete(data)))\n",
    "print('Percent of all seen: {}'.format(sm.percent_all_seen(data)))\n",
    "for t in data[0]:\n",
    "    six.print_(t)\n",
    "# find trajectories that end with everything learned\n",
    "all_learned = []\n",
    "for ix, traj in enumerate(data):\n",
    "    last_knowledge = traj[-1][2]\n",
    "    if np.sum(last_knowledge) > n_concepts - 0.5:\n",
    "        all_learned.append(ix)\n",
    "six.print_(len(all_learned))\n",
    "six.print_(all_learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 7, 10)\n",
      "(100000, 7, 5)\n",
      "(100000, 7, 5)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "input_data_, output_mask_, target_data_ = dataset_utils.preprocess_data_for_rnn(data)\n",
    "train_data = (input_data_[:,:,:], output_mask_[:,:,:], target_data_[:,:,:])\n",
    "six.print_(input_data_.shape)\n",
    "six.print_(output_mask_.shape)\n",
    "six.print_(target_data_.shape)\n",
    "six.print_(input_data_[0,:,:])\n",
    "six.print_(output_mask_[0,:,:])\n",
    "six.print_(target_data_[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vloss shape (50, 11)\n",
      "scores shape (50,)\n",
      " 0: AUC 0.0024 score 1.00\n",
      " 1: AUC 0.0025 score 1.00\n",
      " 2: AUC 0.0016 score 1.00\n",
      " 3: AUC 0.0017 score 1.00\n",
      " 4: AUC 0.0012 score 1.00\n",
      " 5: AUC 0.0018 score 1.00\n",
      " 6: AUC 0.0018 score 0.00\n",
      " 7: AUC 0.0021 score 0.25\n",
      " 8: AUC 0.0021 score 1.00\n",
      " 9: AUC 0.0028 score 1.00\n",
      "10: AUC 0.0023 score 0.00\n",
      "11: AUC 0.0012 score 1.00\n",
      "12: AUC 0.0017 score 1.00\n",
      "13: AUC 0.0021 score 0.00\n",
      "14: AUC 0.0022 score 1.00\n",
      "15: AUC 0.0028 score 0.00\n",
      "16: AUC 0.0024 score 1.00\n",
      "17: AUC 0.0017 score 1.00\n",
      "18: AUC 0.0021 score 0.00\n",
      "19: AUC 0.0025 score 0.00\n",
      "20: AUC 0.0145 score 0.75\n",
      "21: AUC 0.0102 score 0.00\n",
      "22: AUC 0.0099 score 0.00\n",
      "23: AUC 0.0135 score 0.00\n",
      "24: AUC 0.0114 score 0.00\n",
      "25: AUC 0.0085 score 1.00\n",
      "26: AUC 0.0102 score 0.00\n",
      "27: AUC 0.0100 score 0.00\n",
      "28: AUC 0.0106 score 0.00\n",
      "29: AUC 0.0124 score 1.00\n",
      "30: AUC 0.0120 score 0.00\n",
      "31: AUC 0.0134 score 1.00\n",
      "32: AUC 0.0137 score 1.00\n",
      "33: AUC 0.0134 score 0.00\n",
      "34: AUC 0.0116 score 0.00\n",
      "35: AUC 0.0100 score 0.00\n",
      "36: AUC 0.0119 score 0.00\n",
      "37: AUC 0.0102 score 1.00\n",
      "38: AUC 0.0102 score 0.00\n",
      "39: AUC 0.0110 score 0.00\n",
      "40: AUC 0.0108 score 0.00\n",
      "41: AUC 0.0102 score 0.00\n",
      "42: AUC 0.0076 score 0.00\n",
      "43: AUC 0.0102 score 1.00\n",
      "44: AUC 0.0101 score 0.00\n",
      "45: AUC 0.0094 score 0.00\n",
      "46: AUC 0.0087 score 1.00\n",
      "47: AUC 0.0106 score 0.12\n",
      "48: AUC 0.0108 score 0.00\n",
      "49: AUC 0.0096 score 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f88cb6ef410>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD/CAYAAAD/qh1PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88d80f2d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Analyzing results of student2 with 5 skills, with training length 7 and testing length 8.\n",
    "Single LSTM\n",
    "'''\n",
    "data11 = np.load('experiments/test2w5_modelsimple_mid-dropout10-shuffle1-data-test2a-w5-n100000-l7-random.pickle/stats-runB.npz')\n",
    "data12 = np.load('experiments/test2w5_modelsimple_mid-dropout10-shuffle1-data-test2a-w5-n100000-l7-random.pickle/stats-runC.npz')\n",
    "data21 = np.load('experiments/test2w5_modelsimple_mid-dropout10-shuffle1-data-test2a-w5-n100000-l7-random.pickle/mcts-rtype2-rollouts20000-trajectories8-real1-runB.npz')\n",
    "data22 = np.load('experiments/test2w5_modelsimple_mid-dropout10-shuffle1-data-test2a-w5-n100000-l7-random.pickle/mcts-rtype2-rollouts20000-trajectories8-real1-runC.npz')\n",
    "\n",
    "vloss = np.vstack((data11['vloss'],data12['vloss']))\n",
    "scores = np.vstack((data21['scores'],data22['scores']))[:,0]\n",
    "#qvals = np.vstack((data21['qvals'],data22['qvals']))[:,0]\n",
    "\n",
    "six.print_('vloss shape {}'.format(vloss.shape))\n",
    "six.print_('scores shape {}'.format(scores.shape))\n",
    "for i in six.moves.range(scores.shape[0]):\n",
    "    six.print_('{:2d}: AUC {:.4f} score {:.2f}'.format(i, np.sum(vloss[i,:]), scores[i]))\n",
    "\n",
    "plot(np.sum(vloss,axis=1), scores, '.')\n",
    "# from the own qvalues, it seems like as a general rule (though not absolute), larger qvals at the end correspond to better policy-models\n",
    "# 21 / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RNN dynamics model...\n",
      "Directory path for tensorboard summaries: ../tensorboard_logs/test2w5_modelsimple_mid/\n",
      "Checkpoint directory path: ../checkpoints/test2w5_modelsimple_mid/\n",
      "Model loaded.\n",
      "INFO:tensorflow:Restoring parameters from /usr0/home/zguo/Documents/smart-tutor/code/experiments/test2w5_modelsimple_mid-dropout10-shuffle1-data-test2a-w5-n100000-l7-random.pickle/checkpoint-runB6-epoch10\n"
     ]
    }
   ],
   "source": [
    "dmodel = dmc.DynamicsModel(model_id='test2w5_modelsimple_mid', timesteps=seqlen+2, dropout=1.0, load_checkpoint=False)\n",
    "dmodel.load('experiments/test2w5_modelsimple_mid-dropout10-shuffle1-data-test2a-w5-n100000-l7-random.pickle/checkpoint-runB6-epoch10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "State             [      1      0      0      0      0      0      0      0      0      0]\n",
      "Action:           [      0      1      0      0      0]\n",
      "Correct? False\n",
      "Knowledge After:  [      1      0      0      0      0]\n",
      "Model Prediction: [   1.00   0.00   0.00   0.00   0.00]\n",
      "\n",
      "Step 2\n",
      "State             [      1      0      0      0      0      0      1      0      0      0]\n",
      "Action:           [      0      0      1      0      0]\n",
      "Correct? False\n",
      "Knowledge After:  [      1      0      0      0      0]\n",
      "Model Prediction: [   1.00   0.00   0.00   0.00   0.00]\n",
      "\n",
      "Step 3\n",
      "State             [      1      0      0      0      0      0      1      1      0      0]\n",
      "Action:           [      0      1      0      0      0]\n",
      "Correct? False\n",
      "Knowledge After:  [      1      1      0      0      0]\n",
      "Model Prediction: [   1.00   1.00   0.00   0.00   0.00]\n",
      "\n",
      "Step 4\n",
      "State             [      1      1      0      0      0      0      1      1      0      0]\n",
      "Action:           [      0      0      0      0      1]\n",
      "Correct? False\n",
      "Knowledge After:  [      1      1      0      0      0]\n",
      "Model Prediction: [   1.00   1.00   0.00   0.00   0.00]\n",
      "\n",
      "Step 5\n",
      "State             [      1      1      0      0      0      0      1      1      0      1]\n",
      "Action:           [      0      0      0      0      1]\n",
      "Correct? False\n",
      "Knowledge After:  [      1      1      0      0      1]\n",
      "Model Prediction: [   1.00   1.00   0.00   0.00   0.99]\n",
      "\n",
      "Step 6\n",
      "State             [      1      1      0      0      1      0      1      1      0      1]\n",
      "Action:           [      0      0      0      1      0]\n",
      "Correct? False\n",
      "Knowledge After:  [      1      1      0      0      1]\n",
      "Model Prediction: [   1.00   0.99   0.00   0.00   0.99]\n",
      "\n",
      "Step 7\n",
      "State             [      1      1      0      0      1      0      1      1      1      1]\n",
      "Action:           [      0      0      0      1      0]\n",
      "Correct? False\n",
      "Knowledge After:  [      1      1      0      1      1]\n",
      "Model Prediction: [   1.00   0.08   0.00   0.52   0.77]\n",
      "\n",
      "-- Step 8 ----------------------------------------------------------\n",
      "Action:           [      1      0      0      0      0]\n",
      "Correct? 1.0\n",
      "Model Prediction: [   1.00   0.00   0.00   0.00   0.00]\n",
      "\n",
      "Action:           [      0      1      0      0      0]\n",
      "Correct? 1.0\n",
      "Model Prediction: [   1.00   0.29   0.00   0.07   0.20]\n",
      "\n",
      "Action:           [      0      0      1      0      0]\n",
      "Correct? 0.0\n",
      "Model Prediction: [   1.00   0.00   0.00   0.00   0.00]\n",
      "\n",
      "Action:           [      0      0      0      1      0]\n",
      "Correct? 1.0\n",
      "Model Prediction: [   1.00   0.03   0.00   0.87   0.13]\n",
      "\n",
      "Action:           [      0      0      0      0      1]\n",
      "Correct? 1.0\n",
      "Model Prediction: [   1.00   0.08   0.00   0.00   0.79]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict a bit\n",
    "dataix = all_learned[1]\n",
    "test_input_data = input_data_[dataix:dataix+1,:,:]\n",
    "prediction = dmodel.predict(test_input_data)[0,:,:]\n",
    "\n",
    "# print out the predictions after every step\n",
    "curr_data = data[dataix]\n",
    "for t in six.moves.range(7):\n",
    "    six.print_('Step {}'.format(t+1))\n",
    "    six.print_('State             [{}]'.format(''.join('{:7d}'.format(int(x)) for x in curr_data[t][3])))\n",
    "    six.print_('Action:           [{}]'.format(''.join('{:7d}'.format(int(x)) for x in curr_data[t][0])))\n",
    "    six.print_('Correct? {}'.format(curr_data[t][1]))\n",
    "    six.print_('Knowledge After:  [{}]'.format(''.join('{:7d}'.format(int(x)) for x in curr_data[t][2])))\n",
    "    six.print_('Model Prediction: [{}]'.format(''.join('{:7.2f}'.format(x) for x in prediction[t,:])))\n",
    "    six.print_()\n",
    "\n",
    "six.print_('-- Step 8 ----------------------------------------------------------')\n",
    "\n",
    "# add one observation of each action and see what the predictions turn into\n",
    "for nexta in six.moves.range(n_concepts):\n",
    "    actvec = np.zeros((n_concepts,),dtype=np.int)\n",
    "    actvec[nexta] = 1\n",
    "    obvec = np.zeros((n_concepts*2,))\n",
    "    if data[dataix][6][2][nexta] == 1:\n",
    "        obvec[nexta] = 1.0\n",
    "    else:\n",
    "        obvec[nexta + 5] = 1.0\n",
    "    six.print_('Action:           [{}]'.format(''.join('{:7d}'.format(int(x)) for x in actvec)))\n",
    "    six.print_('Correct? {}'.format(data[dataix][6][2][nexta]))\n",
    "    #six.print_('Observation:      [{}]'.format(''.join('{:7d}'.format(int(x)) for x in obvec)))\n",
    "    test_input_data2 = np.vstack((test_input_data[0,:,:],obvec[np.newaxis,:]))\n",
    "    prediction = dmodel.predict(test_input_data2[np.newaxis,:,:])\n",
    "    six.print_('Model Prediction: [{}]'.format(''.join('{:7.2f}'.format(x) for x in prediction[0,7,:])))\n",
    "    six.print_()\n",
    "# observations\n",
    "# sometimes, even though a skill is tested twice, the model doesn't believe it is learned\n",
    "# also if the actions are temporally separated, it seems like the model isn't properly remembering what it has done before\n",
    "# seems like skill 3 is hard to learn properly\n",
    "# also there is still forgetting behavior being learned where testing one problem can reduce the probability of getting another one correct\n",
    "# so it really looks like the central issue is forgetting, and nonindependence\n",
    "# is this caused by overfitting?\n",
    "# maybe need to enlarge the minibatch size by a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
