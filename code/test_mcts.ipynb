{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MCTS with Various Models\n",
    "Here we will test MCTS first with the DKT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%reload_ext autoreload\n",
    "\n",
    "from concept_dependency_graph import ConceptDependencyGraph\n",
    "import data_generator as dg\n",
    "from student import *\n",
    "import simple_mdp as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2-n100000-l6-lp15-random.pickle\n"
     ]
    }
   ],
   "source": [
    "n_concepts = 4\n",
    "use_student2 = True\n",
    "learn_prob = 0.15\n",
    "n_students = 100000\n",
    "seqlen = 6\n",
    "policy = 'random'\n",
    "filename = 'test{}-n{}-l{}-lp{}-{}.pickle'.format('2' if use_student2 else '', n_students, seqlen, int(learn_prob*100), policy)\n",
    "#concept_tree = sm.create_custom_dependency()\n",
    "concept_tree = ConceptDependencyGraph()\n",
    "concept_tree.init_default_tree(n_concepts)\n",
    "if not use_student2:\n",
    "    test_student = Student(n=n_concepts,p_trans_satisfied=learn_prob, p_trans_not_satisfied=0.0, p_get_ex_correct_if_concepts_learned=1.0)\n",
    "else:\n",
    "    test_student = Student2(n_concepts)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing synthetic data sets...\n",
      "Generating data for 100000 students with behavior policy random and sequence length 7.\n",
      "Data generation completed. \n"
     ]
    }
   ],
   "source": [
    "print (\"Initializing synthetic data sets...\")\n",
    "dg.generate_data(concept_tree, student=test_student, n_students=n_students, seqlen=seqlen, policy=policy, filename=\"{}{}\".format(dg.SYN_DATA_DIR, filename))\n",
    "print (\"Data generation completed. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dynamics_model_class as dmc\n",
    "import numpy as np\n",
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RNN dynamics model...\n",
      "Directory path for tensorboard summaries: ../tensorboard_logs/test2_model_mid/\n",
      "Checkpoint directory path: ../checkpoints/test2_model_mid/\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# test_model hidden=16\n",
    "# test_model_small hidden=5\n",
    "# test_model_mid hidden=10\n",
    "dmodel = dmc.DynamicsModel(model_id=\"test2_model_mid\", timesteps=seqlen, load_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load toy data\n",
    "data = dataset_utils.load_data(filename='{}{}'.format(dg.SYN_DATA_DIR, filename))\n",
    "input_data_, output_mask_, target_data_ = dataset_utils.preprocess_data_for_rnn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 6, 8)\n",
      "(100000, 6, 4)\n",
      "(100000, 6, 4)\n"
     ]
    }
   ],
   "source": [
    "train_data = (input_data_[:,:,:], output_mask_[:,:,:], target_data_[:,:,:])\n",
    "print(input_data_.shape)\n",
    "print(output_mask_.shape)\n",
    "print(target_data_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7034  | total loss: \u001b[1m\u001b[32m0.00153\u001b[0m\u001b[0m | time: 19.774s\n",
      "| Adam | epoch: 005 | loss: 0.00153 -- iter: 89984/90000\n",
      "Training Step: 7035  | total loss: \u001b[1m\u001b[32m0.00151\u001b[0m\u001b[0m | time: 20.950s\n",
      "| Adam | epoch: 005 | loss: 0.00151 | val_loss: 0.00155 -- iter: 90000/90000\n",
      "--\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_2.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "dmodel.train(train_data, n_epoch=5, load_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n",
      "[[0.7310575246810913, 0.0005168265197426081, 0.0005419104709289968, 1.4160171701860236e-07], [0.8807966709136963, 0.0003708214790094644, 0.880794107913971, 4.6009071752450836e-07], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "preds = dmodel.predict(input_data_[:1,:2, :])\n",
    "print len(preds)\n",
    "print len(preds[0])\n",
    "print preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnnsim = dmc.RnnStudentSim(dmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from mcts import *\n",
    "actix = 0\n",
    "actvec = np.zeros((n_concepts,))\n",
    "actvec[actix] = 1\n",
    "act = StudentAction(actix, actvec)\n",
    "print rnnsim.sequence\n",
    "print rnnsim.sample_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnnsim.advance_simulator(act, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]\n",
      "[0.7301660180091858, 0.020661335438489914, 0.030488919466733932, 0.00025640291278250515]\n",
      "0.781572675827\n"
     ]
    }
   ],
   "source": [
    "print rnnsim.sequence\n",
    "print rnnsim.sample_observations()\n",
    "print rnnsim.sample_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
