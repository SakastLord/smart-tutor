{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing MCTS with Various Models\n",
    "Here we will test MCTS first with the DKT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import six\n",
    "from concept_dependency_graph import ConceptDependencyGraph\n",
    "import data_generator as dg\n",
    "from student import *\n",
    "import simple_mdp as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2a-n100000-l5-random.pickle\n"
     ]
    }
   ],
   "source": [
    "n_concepts = 4\n",
    "use_student2 = True\n",
    "transition_after = True\n",
    "student2_str = ('2' if use_student2 else '') + ('a' if use_student2 and transition_after else '')\n",
    "learn_prob = 0.5\n",
    "lp_str = '-lp{}'.format(int(learn_prob*100)) if not use_student2 else ''\n",
    "n_students = 100000\n",
    "seqlen = 5\n",
    "filter_mastery = False\n",
    "filter_str = '' if not filter_mastery else '-filtered'\n",
    "policy = 'random'\n",
    "epsilon = 0.3\n",
    "epsilon_str = '{:.2f}'.format(epsilon) if policy == 'egreedy' else ''\n",
    "filename = 'test{}-n{}-l{}{}-{}{}{}.pickle'.format(student2_str, n_students, seqlen,\n",
    "                                                    lp_str, policy, epsilon_str, filter_str)\n",
    "#concept_tree = sm.create_custom_dependency()\n",
    "concept_tree = ConceptDependencyGraph()\n",
    "concept_tree.init_default_tree(n_concepts)\n",
    "if not use_student2:\n",
    "    test_student = Student(n=n_concepts,p_trans_satisfied=learn_prob, p_trans_not_satisfied=0.0, p_get_ex_correct_if_concepts_learned=1.0)\n",
    "else:\n",
    "    test_student = Student2(n_concepts, transition_after=transition_after)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing synthetic data sets...\n",
      "Generating data for 100000 students with behavior policy random and sequence length 5.\n",
      "Data generation completed. \n"
     ]
    }
   ],
   "source": [
    "# Generates the data\n",
    "# Only run this cell if need to generate new data, otherwise skip this\n",
    "if False:\n",
    "    print (\"Initializing synthetic data sets...\")\n",
    "    dg.generate_data(concept_tree, student=test_student, n_students=n_students, filter_mastery=filter_mastery, seqlen=seqlen, policy=policy, epsilon=epsilon, filename=\"{}{}\".format(dg.SYN_DATA_DIR, filename))\n",
    "    print (\"Data generation completed. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dynamics_model_class as dmc\n",
    "import mcts_tests as mc\n",
    "import mcts\n",
    "import numpy as np\n",
    "import dataset_utils\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load toy data\n",
    "data = dataset_utils.load_data(filename='{}{}'.format(dg.SYN_DATA_DIR, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average posttest: 0.4377175\n",
      "Average sparse reward: 0.0\n",
      "Percent of full posttest score: 0.0\n",
      "Percent of all seen: 0.38222\n",
      "[(array([ 0.,  0.,  1.,  0.]), False, array([ 1.,  0.,  0.,  0.])), (array([ 0.,  0.,  0.,  1.]), False, array([ 1.,  0.,  0.,  0.])), (array([ 0.,  1.,  0.,  0.]), False, array([ 1.,  0.,  0.,  0.])), (array([ 0.,  0.,  1.,  0.]), False, array([ 1.,  0.,  1.,  0.])), (array([ 1.,  0.,  0.,  0.]), True, array([ 1.,  0.,  1.,  0.]))]\n"
     ]
    }
   ],
   "source": [
    "print('Average posttest: {}'.format(sm.expected_reward(data)))\n",
    "print('Average sparse reward: {}'.format(sm.expected_sparse_reward(data)))\n",
    "print('Percent of full posttest score: {}'.format(sm.percent_complete(data)))\n",
    "print('Percent of all seen: {}'.format(sm.percent_all_seen(data)))\n",
    "six.print_(data[0])\n",
    "input_data_, output_mask_, target_data_ = dataset_utils.preprocess_data_for_rnn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5, 8)\n",
      "(100000, 5, 4)\n",
      "(100000, 5, 4)\n",
      "[[ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "train_data = (input_data_[:,:,:], output_mask_[:,:,:], target_data_[:,:,:])\n",
    "print(input_data_.shape)\n",
    "print(output_mask_.shape)\n",
    "print(target_data_.shape)\n",
    "six.print_(input_data_[0,:,:])\n",
    "six.print_(output_mask_[0,:,:])\n",
    "six.print_(target_data_[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RNN dynamics model...\n",
      "Directory path for tensorboard summaries: ../tensorboard_logs/test2_model_small/\n",
      "Checkpoint directory path: ../checkpoints/test2_model_small/\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# test_model hidden=16\n",
    "# test_model_mid hidden=10\n",
    "# test_model_small hidden=5\n",
    "# test_model_tiny hidden=3\n",
    "model_id = \"test2_model_small\"\n",
    "dmodel = dmc.DynamicsModel(model_id=model_id, timesteps=seqlen, dropout=1.0, load_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExtractCallback(tflearn.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.tstate = None\n",
    "    def on_epoch_end(self, training_state):\n",
    "        self.tstate = copy.copy(training_state)\n",
    "ecall = ExtractCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14069  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 6.547s\n",
      "| Adam | epoch: 010 | loss: 0.00088 -- iter: 89984/90000\n",
      "Training Step: 14070  | total loss: \u001b[1m\u001b[32m0.00087\u001b[0m\u001b[0m | time: 7.714s\n",
      "| Adam | epoch: 010 | loss: 0.00087 | val_loss: 0.00085 -- iter: 90000/90000\n",
      "--\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_2.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "dmodel.train(train_data, n_epoch=10, callbacks=ecall, load_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'acc_value', 'best_accuracy', 'current_iter', 'epoch', 'global_acc', 'global_loss', 'increaseEpoch', 'increaseStep', 'loss_value', 'resetGlobal', 'step', 'step_time', 'step_time_total', 'update', 'val_acc', 'val_loss']\n",
      "0.000871833821293\n",
      "0.000853506263532\n"
     ]
    }
   ],
   "source": [
    "print(dir(ecall.tstate))\n",
    "print(ecall.tstate.global_loss)\n",
    "print(ecall.tstate.val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_2.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "# save the model to a checkpoint file\n",
    "chkpt = 'tempmodel'\n",
    "dmodel.save(chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RNN dynamics model...\n",
      "Directory path for tensorboard summaries: ../tensorboard_logs/test2_model_small/\n",
      "Checkpoint directory path: ../checkpoints/test2_model_small/\n",
      "Model loaded.\n",
      "INFO:tensorflow:Restoring parameters from /usr0/home/zguo/Documents/smart-tutor/code/tempmodel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100.0, 93.971984540507989)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model on the real environment\n",
    "test_horizon = 6\n",
    "n_rollouts = 1000\n",
    "n_trajectories = 100\n",
    "r_type = mcts.SPARSE\n",
    "\n",
    "test_student = Student2(n_concepts, transition_after=transition_after)\n",
    "test_student.reset()\n",
    "test_student.knowledge[0] = 1 # initialize the first concept to be known\n",
    "sim = StudentExactSim(test_student.copy(), concept_tree)\n",
    "\n",
    "mc.test_dkt_chunk(n_trajectories, concept_tree, sim, model_id, chkpt, test_horizon, n_rollouts, False, r_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
